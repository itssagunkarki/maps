[
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "maps",
    "section": "",
    "text": "import os\nimport dotenv\nfrom datetime import datetime\nimport pandas as pd\nimport numpy as np\nimport time\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\npd.set_option('display.max_columns', 500)\n\ndotenv.load_dotenv()\nfrom data_processing.omaha import *\n\n\ngeoJSON = get_geo_json()\n\n\ngeoJSON['features'][0]\n\n{'id': '0',\n 'type': 'Feature',\n 'properties': {'GISJOIN': 'G31005500002001',\n  'STATEFP': '31',\n  'COUNTYFP': '055',\n  'TRACTCE': '000200',\n  'BLKGRPCE': '1',\n  'GEOID': '310550002001',\n  'NAMELSAD': 'Block Group 1',\n  'MTFCC': 'G5030',\n  'FUNCSTAT': 'S',\n  'ALAND': 343095.0,\n  'AWATER': 0.0,\n  'INTPTLAT': '+41.3224766',\n  'INTPTLON': '-095.9516873',\n  'Shape_Leng': 2757.0171445,\n  'Shape_Area': 343094.450371},\n 'geometry': {'type': 'Polygon',\n  'coordinates': (((-95.9455880000813, 41.32322900002993),\n    (-95.94556800014433, 41.323140999654115),\n    (-95.94554300035315, 41.32278499987112),\n    (-95.94552400003063, 41.322290000707),\n    (-95.94554599979247, 41.3217460002031),\n    (-95.94557600024395, 41.32129700048155),\n    (-95.94577799992875, 41.32130500005777),\n    (-95.94681200038337, 41.32130699963915),\n    (-95.94691100049992, 41.32136799977498),\n    (-95.94691899923502, 41.32068000001284),\n    (-95.94704700007144, 41.32067300026797),\n    (-95.94932099954255, 41.320673000195605),\n    (-95.95189200027448, 41.320672000569594),\n    (-95.95402500045304, 41.32067499947118),\n    (-95.95654399979394, 41.32067499995682),\n    (-95.95654200062744, 41.32118999988485),\n    (-95.95654400023156, 41.32144400004967),\n    (-95.95653199949874, 41.32214599958283),\n    (-95.95657699994544, 41.32259299981858),\n    (-95.95664600048559, 41.32291700020423),\n    (-95.95685600036457, 41.32367400050524),\n    (-95.95706499962868, 41.32440899998601),\n    (-95.95690699931629, 41.324454000599324),\n    (-95.9566180004756, 41.32448800015007),\n    (-95.95643100016495, 41.324456000498046),\n    (-95.95636800066683, 41.32445299983057),\n    (-95.95426500035079, 41.32445300043866),\n    (-95.95110000059503, 41.32445100034626),\n    (-95.94917599996734, 41.32444899976161),\n    (-95.94885999996035, 41.32445399984224),\n    (-95.94863899980155, 41.32367300029093),\n    (-95.94860500045817, 41.323552000007915),\n    (-95.94853799961444, 41.323285999958145),\n    (-95.94851799932543, 41.32313899992469),\n    (-95.94850999994051, 41.322947000248114),\n    (-95.94691599932379, 41.32294600019697),\n    (-95.9469159998294, 41.323221999868494),\n    (-95.94682699992093, 41.323227000372334),\n    (-95.94581699958323, 41.323223999839456),\n    (-95.9455880000813, 41.32322900002993)),)},\n 'bbox': (-95.95706499962868,\n  41.320672000569594,\n  -95.94552400003063,\n  41.32448800015007)}\n\n\n\ndf_joined = get_df_joined()\n\n\nreturn_kiosk_GEOID = df_joined[['GEOID', 'Return Kiosk']].drop_duplicates().set_index('Return Kiosk')['GEOID'].to_dict()\nreturn_kiosk_GEOID\n\n{'Miller Park': '310550003002',\n 'Shop HQ/Event': '310550005002',\n '11th and Capitol': '310550005002',\n 'Kiewit Luminarium': '310550005002',\n '10th & Cass': '310550005002',\n 'Lewis & Clark Landing': '310550005002',\n '10th & Fahey': '310550005002',\n 'Bob Kerrey Pedestrian Bridge': '310550005002',\n '1516 Cuming St': '310550005002',\n '12th & Davenport': '310550005002',\n '14th & Fahey': '310550005002',\n '4/20 Event (Gray) 1.0': '310550005002',\n '13th & Nicholas': '310550005002',\n 'Heartland Bike Share Help Desk': '310550005002',\n 'LIBRARY HELP DESK': '310550005002',\n '24th & Lake': '310550011002',\n '24th & Wirt St': '310550011002',\n '23rd & Cuming': '310550012003',\n '29th & California (The Atlas)': '310550016001',\n 'Bike Union': '310550016002',\n '19th & California': '310550016002',\n '12th & Leavenworth': '310550018001',\n '11th & Jackson': '310550018002',\n '12th & Harney': '310550018002',\n '13th & Dodge': '310550018002',\n 'Breakers Apartments': '310550018002',\n 'The Durham Museum': '310550018002',\n '9th & Jones': '310550018002',\n '10th & Farnam': '310550018002',\n '10th & Harney': '310550018002',\n '13th & Farnam': '310550018002',\n '7th & Jones': '310550018002',\n '10th & Douglas': '310550018002',\n '8th & Farnam': '310550018002',\n '1819 Farnam': '310550018003',\n \"17th & St Mary's\": '310550018003',\n '14th & Jones': '310550018003',\n 'W. Dale Clark Library: 15th & Farnam': '310550018003',\n '15th & Howard': '310550018003',\n '16th & Harney': '310550018003',\n '19th & Douglas (ORBT)': '310550018003',\n '16th & Douglas': '310550018003',\n '14th & Douglas': '310550018003',\n '20th & Dodge': '310550018003',\n '24th & Farnam': '310550019001',\n '22nd & St. Mary': '310550019001',\n '24th & Dodge': '310550019001',\n '13th & William': '310550021001',\n '19th & Vinton': '310550024003',\n '24th & J': '310550026001',\n '28th Ave & Q St': '310550031004',\n '24th & N': '310550032002',\n 'Park Avenue & Woolworth': '310550038002',\n 'Midtown Crossing: 32nd & Farnam': '310550040002',\n '24th Ave & Harney': '310550040002',\n '31st & Harney (Dewey Park)': '310550040003',\n '34th & Farnam': '310550042001',\n '36th & Farnam': '310550042001',\n '40th & Farnam': '310550043001',\n '38th & Farnam': '310550043001',\n '39th & Jackson': '310550043002',\n '42nd & Dewey': '310550043002',\n '40th & Leavenworth': '310550043003',\n '45th & Emile': '310550044001',\n '44th & Farnam': '310550044001',\n 'University Drive South: Maverick Village': '310550047002',\n 'Arts & Sciences Hall': '310550047002',\n '62nd & Dodge (Retired)': '310550047002',\n '62nd & Dodge': '310550047002',\n '50th & Underwood': '310550048003',\n '49th & Dodge': '310550048004',\n \"Ben's House\": '310550048004',\n '40th & Hamilton': '310550049001',\n '33rd & California': '310550051002',\n '30th & Patrick': '310550052001',\n '63rd & Maple': '310550056004',\n '60th & Maple': '310550057002',\n 'NOTC 31st Ave & Taylor': '310550059021',\n 'MCC Fort Bookstore N 32nd St': '310550061025',\n 'MCC North 30th St': '310550061025',\n '72nd & Dodge': '310550067011',\n '77th & Dodge': '310550067011',\n 'College of Saint Mary': '310550070011',\n '67th & Frances': '310550070012',\n '66th & Center': '310550070012',\n 'Aksarben Drive': '310550070012',\n '64th & Pine': '310550070012',\n '67th & Pine': '310550070012',\n 'Prairie Queen Recreation Area (Papillion)': '311530106291'}\n\n\n\nreturn_kiosk_lst = list(return_kiosk_GEOID.keys())\nreturn_kiosk_lst\n\n['Miller Park',\n 'Shop HQ/Event',\n '11th and Capitol',\n 'Kiewit Luminarium',\n '10th & Cass',\n 'Lewis & Clark Landing',\n '10th & Fahey',\n 'Bob Kerrey Pedestrian Bridge',\n '1516 Cuming St',\n '12th & Davenport',\n '14th & Fahey',\n '4/20 Event (Gray) 1.0',\n '13th & Nicholas',\n 'Heartland Bike Share Help Desk',\n 'LIBRARY HELP DESK',\n '24th & Lake',\n '24th & Wirt St',\n '23rd & Cuming',\n '29th & California (The Atlas)',\n 'Bike Union',\n '19th & California',\n '12th & Leavenworth',\n '11th & Jackson',\n '12th & Harney',\n '13th & Dodge',\n 'Breakers Apartments',\n 'The Durham Museum',\n '9th & Jones',\n '10th & Farnam',\n '10th & Harney',\n '13th & Farnam',\n '7th & Jones',\n '10th & Douglas',\n '8th & Farnam',\n '1819 Farnam',\n \"17th & St Mary's\",\n '14th & Jones',\n 'W. Dale Clark Library: 15th & Farnam',\n '15th & Howard',\n '16th & Harney',\n '19th & Douglas (ORBT)',\n '16th & Douglas',\n '14th & Douglas',\n '20th & Dodge',\n '24th & Farnam',\n '22nd & St. Mary',\n '24th & Dodge',\n '13th & William',\n '19th & Vinton',\n '24th & J',\n '28th Ave & Q St',\n '24th & N',\n 'Park Avenue & Woolworth',\n 'Midtown Crossing: 32nd & Farnam',\n '24th Ave & Harney',\n '31st & Harney (Dewey Park)',\n '34th & Farnam',\n '36th & Farnam',\n '40th & Farnam',\n '38th & Farnam',\n '39th & Jackson',\n '42nd & Dewey',\n '40th & Leavenworth',\n '45th & Emile',\n '44th & Farnam',\n 'University Drive South: Maverick Village',\n 'Arts & Sciences Hall',\n '62nd & Dodge (Retired)',\n '62nd & Dodge',\n '50th & Underwood',\n '49th & Dodge',\n \"Ben's House\",\n '40th & Hamilton',\n '33rd & California',\n '30th & Patrick',\n '63rd & Maple',\n '60th & Maple',\n 'NOTC 31st Ave & Taylor',\n 'MCC Fort Bookstore N 32nd St',\n 'MCC North 30th St',\n '72nd & Dodge',\n '77th & Dodge',\n 'College of Saint Mary',\n '67th & Frances',\n '66th & Center',\n 'Aksarben Drive',\n '64th & Pine',\n '67th & Pine',\n 'Prairie Queen Recreation Area (Papillion)']\n\n\n\nget_return_kiosk_GEOID(\"Miller Park\")\n\n'310550003002'\n\n\n\ncurr = None\nfor i in geoJSON['features']:\n    # print(i['properties']['GEOID'])\n    if i['properties']['GEOID'] == get_return_kiosk_GEOID(\"Miller Park\"):\n        curr = i\n        break\n\n\nimport plotly.express as px\n\ndef join_with_omaha_area(current_section, omaha_region_gdf):\n    \"\"\"\n    Join the current section with the omaha region\n    \"\"\"\n    return gpd.sjoin(omaha_region_gdf, current_section, how='left', predicate='intersects').reset_index().fillna(0)\n\ndef plot_map(df, column_to_plot, title):\n    \"\"\"\n    Plot the map using Plotly\n    \"\"\"\n    fig = px.choropleth_mapbox(df, geojson=df.geometry, locations=df.index, color=column_to_plot,\n                            #    color_continuous_scale=[[0, 'red'], [1, 'blue']],\n                               range_color=[df[column_to_plot].min(), df[column_to_plot].max()],\n                               mapbox_style=\"carto-positron\",\n                               zoom=10,\n                               opacity=0.5,\n                               hover_name=df.index,\n                               labels={column_to_plot: column_to_plot})\n    \n    fig.update_layout(\n        title=title,\n        mapbox_style=\"carto-positron\",\n        mapbox_zoom=10,  # Adjust the zoom level as needed\n        mapbox_center={\"lat\": 41.3148, \"lon\": -96.1951},  # Centered at Douglas County, Nebraska\n        margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0}\n    )\n\n    fig.show()\n\n\ncurrent_section = df_joined[df_joined['Return_Kiosk_Coordinates'] == '41.25518,-95.98054']\nplot_map(df=current_section,\n         column_to_plot='BT_dividedby_TT',\n         title='Bike to Transit Ratio')\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\nclass Solution:\n    def rotate(self, matrix) -&gt; None:\n        \"\"\"\n        Do not return anything, modify matrix in-place instead.\n        \"\"\"\n        m,n = len(matrix), len(matrix[0])\n\n        # Flip diagonally\n        for i in range(m):\n            for j in range(n-i):\n                matrix[m-1-i][j], matrix[j][m-1-i] = matrix[j][m-1-i], matrix[m-1-i][j]\n\n        # Flip vertically\n        for i in range(m//2):\n            for j in range(n):\n                matrix[i][j], matrix[m-i-1][n-1] = matrix[m-i-1][n-1], matrix[i][j]\n\n\nmatrix = [[1,2,3],[4,5,6],[7,8,9]]\nSolution().rotate(matrix)\n    \nmatrix\n\n[[9, 1, 4], [2, 5, 8], [3, 6, 7]]\n\n\n\nclass Solution:\n    def rotate(self, matrix) -&gt; None:\n        \"\"\"\n        Do not return anything, modify matrix in-place instead.\n        \"\"\"\n        m, n = len(matrix), len(matrix[0])\n\n        # Flip diagonally\n        for i in range(m):\n            for j in range(i):  # Change: range(i), not range(n-i) \n                matrix[i][j], matrix[j][i] = matrix[j][i], matrix[i][j]\n\n        # Flip horizontally (this part is correct)\n        for i in range(m // 2):\n            for j in range(n):\n                matrix[i][j], matrix[m - i - 1][j] = matrix[m - i - 1][j], matrix[i][j]\n\nmatrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\nSolution().rotate(matrix)\nprint(matrix)\n\n[[3, 6, 9], [2, 5, 8], [1, 4, 7]]\n\n\n\nclass Solution:\n    def rotate(self, matrix) -&gt; None:\n        \"\"\"\n        Do not return anything, modify matrix in-place instead.\n        \"\"\"\n        m, n = len(matrix), len(matrix[0])\n\n        # Flip diagonally\n        for i in range(len(matrix)):\n            for j in range(i):\n                matrix[i][j], matrix[j][i] = matrix[j][i], matrix[i][j]\n\n\n        # Flip vertically\n        for i in range(len(matrix)):\n            for j in range(len(matrix[0])//2):\n                matrix[i][j], matrix[i][n-1-j] = matrix[i][n-1-j], matrix[i][j] \n\nmatrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\nSolution().rotate(matrix)\nprint(matrix)\n\n[[7, 4, 1], [8, 5, 2], [9, 6, 3]]\n\n\n\nclass Solution:\n    def rotate(self, matrix) -&gt; None:\n        \"\"\"\n        Do not return anything, modify matrix in-place instead.\n        \"\"\"\n        # Transpose the matrix\n        for i in range(len(matrix)):\n            for j in range(i):\n                matrix[i][j], matrix[j][i] = matrix[j][i], matrix[i][j]\n\n        # Reverse each column \n        for i in range(len(matrix)):\n            matrix[i].reverse()  # Or equivalently: matrix[i] = matrix[i][::-1]\n\nmatrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\nSolution().rotate(matrix)\nprint(matrix)\n\n[[7, 4, 1], [8, 5, 2], [9, 6, 3]]"
  },
  {
    "objectID": "daily_avg.html",
    "href": "daily_avg.html",
    "title": "maps",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\nimport geopandas as gpd\n\npd.set_option('display.max_columns', None)\n\n\n## read json\nimport json\nwith open('/Users/sagunkarki/Desktop/mitralab/POWERDataset/data/data_generated/temperature_fromPOWER/55119.json') as f:\n    data = json.load(f)\n\n\ndf= pd.read_parquet('/Users/sagunkarki/Desktop/mitralab/POWERDataset/data/data_generated/yearly_temperature/temperature_2010.parquet')\n\n\nhrs = ['00:00:00', '01:00:00', '02:00:00', '03:00:00', '04:00:00',\n       '05:00:00', '06:00:00', '07:00:00', '08:00:00', '09:00:00', '10:00:00',\n       '11:00:00', '12:00:00', '13:00:00', '14:00:00', '15:00:00', '16:00:00',\n       '17:00:00', '18:00:00', '19:00:00', '20:00:00', '21:00:00', '22:00:00',\n       '23:00:00']\n\ndf['Avg'] = df[hrs].mean(axis=1)  \ndf.drop(hrs, axis=1, inplace=True)\n\n## convert to farhenheit\ndf['Avg'] = df['Avg']*9/5 + 32\n\n\ndf['FIPS'] = df['FIPS'].astype(int)\ndf['date'] = pd.to_datetime(df['date'])\ndf.dtypes\n\ndate    datetime64[ns]\nFIPS             int64\nAvg            float64\ndtype: object\n\n\n\ndf\n\n\n\n\n\n\n\n\n\ndate\nFIPS\nAvg\n\n\n\n\n0\n2010-01-01\n19159\n2.67650\n\n\n1\n2010-01-02\n19159\n-7.39600\n\n\n2\n2010-01-03\n19159\n1.42925\n\n\n3\n2010-01-04\n19159\n-8.41000\n\n\n4\n2010-01-05\n19159\n-7.90825\n\n\n...\n...\n...\n...\n\n\n385070\n2010-12-27\n19157\n13.18925\n\n\n385071\n2010-12-28\n19157\n20.48450\n\n\n385072\n2010-12-29\n19157\n27.58475\n\n\n385073\n2010-12-30\n19157\n39.56825\n\n\n385074\n2010-12-31\n19157\n33.04475\n\n\n\n\n385075 rows × 3 columns\n\n\n\n\n\ndf_us_counties = pd.read_csv(\"/Users/sagunkarki/Desktop/mitralab/POWERDataset/data/data_generated/midwest_counties_centroid/midwest_counties_centroid.csv\")\n\n\ndf_us_counties.dtypes\n\nNAME           object\nSTATE_NAME     object\nFIPS            int64\nlat           float64\nlon           float64\ndtype: object\n\n\n\nstart_date = '2010-04-01'\nend_date = '2010-10-01'\n\nstart_date = datetime.datetime.strptime(start_date, '%Y-%m-%d')\nend_date = datetime.datetime.strptime(end_date, '%Y-%m-%d')\n\n\ndf = df[df['date'] &lt; end_date]\ndf = df[df['date'] &gt; start_date]\n\n\ndf_merged = pd.merge(df, df_us_counties, left_on='FIPS', right_on='FIPS')\n\n\ndf_merged.to_csv('test.csv')\n\n\ndf_merged\n\n\n\n\n\n\n\n\n\ndate\nFIPS\nAvg\nNAME\nSTATE_NAME\nlat\nlon\n\n\n\n\n0\n2010-04-02\n19159\n63.66350\nRinggold County\nIowa\n40.735410\n-94.243979\n\n\n1\n2010-04-03\n19159\n48.48275\nRinggold County\nIowa\n40.735410\n-94.243979\n\n\n2\n2010-04-04\n19159\n52.12025\nRinggold County\nIowa\n40.735410\n-94.243979\n\n\n3\n2010-04-05\n19159\n52.80575\nRinggold County\nIowa\n40.735410\n-94.243979\n\n\n4\n2010-04-06\n19159\n68.80025\nRinggold County\nIowa\n40.735410\n-94.243979\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n192005\n2010-09-26\n19157\n51.26075\nPoweshiek County\nIowa\n41.686691\n-92.531478\n\n\n192006\n2010-09-27\n19157\n52.37075\nPoweshiek County\nIowa\n41.686691\n-92.531478\n\n\n192007\n2010-09-28\n19157\n59.50925\nPoweshiek County\nIowa\n41.686691\n-92.531478\n\n\n192008\n2010-09-29\n19157\n60.17900\nPoweshiek County\nIowa\n41.686691\n-92.531478\n\n\n192009\n2010-09-30\n19157\n61.26425\nPoweshiek County\nIowa\n41.686691\n-92.531478\n\n\n\n\n192010 rows × 7 columns\n\n\n\n\n\ndfx = df_merged[df_merged['FIPS'] == 19159]\nplt.plot(dfx['date'], dfx['Avg'])\n\n\n\n\n\n\n\n\n\nimport plotly.express as px\nimport pandas as pd\n\n# Sample time series data for map (latitude, longitude, value, and date)\ndata = {\n    \"date\": df_merged['date'],\n    \"latitude\": df_merged['lat'],\n    \"longitude\": df_merged['lon'],\n    \"value\": df_merged['Avg']\n}\n\ndf = pd.DataFrame(data)\n\n# Create the time series map focusing on the US\nfig = px.scatter_geo(df, \n                     lat='latitude', \n                     lon='longitude', \n                     color='value', \n                     animation_frame='date',\n                     size='value',\n                     hover_name='value',\n                     scope='usa',  # Focus on the United States\n                     title='Time Series Map - US Focus')\n\n# Show the map\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  }
]